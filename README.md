# ml21fall

This repository contains coursework for a Machine Learning course (NTU, Fall 2021), instructed by Hsuan-Tien Lin. It includes homework assignments, solutions, and a final project.

## Homework Assignments

The repository includes materials for Homework 1 through Homework 6. Each homework directory (`hw1` through `hw6`) typically contains:
* A PDF file with the assignment questions (e.g., `ML2021_HW1.pdf`).
* Python scripts (`.py`) which appear to be implementations or solutions for specific questions (e.g., `PLA_algorithm.py` in `hw1`, `Q14.py` in `hw4` which uses LIBLINEAR).
* PDF files with solutions (e.g., `Final_sol.pdf` in `hw1`, `Solution.pdf` in `hw2`).

Topics covered in the homeworks include:
* The Learning Problem, Perceptron Learning Algorithm (PLA) (Homework 1)
* Regularization, VC Dimension, Bias-Variance Tradeoff (Homework 2, 3, 4)
* Support Vector Machines (SVM), Kernel Methods (Homework 4, 5)
* Decision Trees, Random Forests (Homework 6)

## Final Project

The `finalproject` directory contains a project that appears to focus on **telecom customer churn prediction**.
The project involves several stages:
* **Data Merging**: The `finalproject/merge.py` script combines various CSV datasets located in `finalproject/dataset/`. These datasets include customer demographics, location data, population statistics, service usage, satisfaction scores, and churn status. The merged data is saved as `merge.csv`.
* **Data Preprocessing**: The `finalproject/preprocess.py` script performs data cleaning, transformation (e.g., using LabelEncoder), and likely feature engineering. The preprocessed data appears to be saved as `merge_after_preprocessing.csv`.
* **Model Training and Testing**: While `main.py` and `test.py` in the `finalproject` directory suggest model training and evaluation, their specific implementations are not fully detailed in the provided snippets. `sample_submission.csv` suggests a prediction task where churn categories are predicted for test customer IDs.

## Datasets

The primary datasets used in this repository are for the final project, located in the `finalproject/dataset/` directory. These include:
* `Test_IDs.csv`
* `Train_IDs.csv`
* `demographics.csv`
* `location.csv`
* `merge.csv` (Generated by `merge.py`)
* `merge_after_preprocessing.csv` (Generated by `preprocess.py`)
* `population.csv`
* `sample_submission.csv`
* `satisfaction.csv`
* `services.csv`
* `status.csv`

Additionally, homework assignments might utilize other datasets, such as `hw4_train.txt`, `hw4_test.txt`, `satimage.scale.txt`, and `satimage.scale.t.txt`.

## Code Structure

The repository is organized into directories for each homework (`hw1` to `hw6`) and a `finalproject` directory. Python scripts within these directories implement algorithms and solutions related to the respective assignments or project components. Common libraries used include `numpy`, `pandas`, `matplotlib`, and `scikit-learn`. The final project also utilizes `glob` and `os` for file system operations. Some homework assignments (e.g., `hw4`) use the `LIBLINEAR` library.

---

This README provides a general overview. For specific details on each homework or the final project, please refer to the respective directories and files.
